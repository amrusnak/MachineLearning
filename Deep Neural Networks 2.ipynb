{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using He initializaton rather than Xavier (default for layers.dense)\n",
    "he_init = tf.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden1 =tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, kernel_initializer=he_init,name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preventing activation function saturating\n",
    "#leaky relu\n",
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEMCAYAAAALXDfgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8VNW99/HPjwCScEckReoBRcRrQY1XKgaqeKu3x9YHFVu0GLRSrQexPBYLBTlqvVSqqIAoiqBYW62KcKpgUFqOFRQPpSqKQkVBUAgQQhKYrOePNcAQQjK5TNZcvu/Xa17ZM7Oz93d2dn6zZs3ae5tzDhERSS1NQgcQEZHaU/EWEUlBKt4iIilIxVtEJAWpeIuIpCAVbxGRFKTinSLMrNDMHg6dIx2YWb6ZOTPr2AjrWmVmtzbCeo40s0VmVmpmqxK9vjjyODP7Uegc6UzFuwGY2TQzezV0jtqKviG46K3czFaa2V1mdkAtlzPYzIprWM8+bzw1/V5D2E/x/DvQGfi2Adczxsz+WcVTJwGPNNR6qnEnUAIcGV1no6hm3+8MvNJYOTJR09ABJLgngduB5vh/+iejj/+/YIkSzDlXDqxrpHVtaIz1AIcDf3HOrWqk9VXLOdco2zeTqeXdCMysrZlNNrP1ZrbVzBaYWV7M8wea2bNmtsbMtpvZcjO7poZl/sDMiszsejPra2Y7zOw7leYZb2b/W0O8EufcOufcv51zfwJeBwZUWk4XM3vOzDZFb7PNrEctN0OdmNndZvZxdLusMrPfmVmLSvOcb2bvROf51sxeMbMWZlYIdAXu3fUJIzr/7m4TM2sT/b0LKy1zQHSbdqoph5kNBkYDx8R8khkcfW6vlr+Z/YeZvRjdD7aa2Z/N7Lsxz48xs3+a2cDoJ6GtZvZSdV080dfVC/hNdN1jzKxbdDqv8ry7ujNi5rnMzF43sxIz+5eZnV3pd440s5fNbLOZFUe7Z44zszHAT4ELYl53fuX1RO8fZ2ZvRLffxmiLvW3M89PM7FUzu9nMvozuZ0+aWc7+XnemU/FOMDMzYDbQBfghcDzwFjDfzDpHZ2sBvBd9/hhgAjDJzH6wn2X+CHgRKHDOPeacewtYCfwkZp4m0ftTa5G1F9AH2BHzWA7wJlAKnAmcBqwF3mikf6xtwLXAUcDPgYHAr2PynQu8jH/TORHoByzA79v/B1gDjMV/jO9MJc65LfiP91dVeuoq4HXn3Po4cswC7gc+jlnPrMrriv5N/gLkRnP2Aw4GXoruJ7t0A/4vcCn+jfR4YPx+tg/R9X0czdAZuK+aeasyHvgD/g3gXeA5M2sVzXwwsBBwwNnACcBEICu6nueBN2Je99+reN0tgf8GioGTo6/rdOCJSrOeARwLnMWe139zLV9L5nDO6VbPGzANeHU/z/XH77TZlR5fCtxWzTKfAx6PuV8IPAwUAJuBAZXmvxX4MOb+eUAZcGA16ygEyqP5yvD/oBHgsph5rgU+ASzmsSx8f/Hl0fuDgeIa1vNwFY9X+3v7Wdb1wKcx9/8GPFfN/KuAWys9lh99rR2j9y/C9xe3jt7PBrYAV9Yixxjgn9WtH1/8IkC3mOcPAyqAs2KWUwq0jZnn17Hr2k+efwJjYu53i77GvErzOeBHleYZGvN8l+hj34/eHw+sBprXZt+vtJ7rovts6yr+BofHLOcLICtmninAG3X5n8yEm1reiXcikANsiH7kLDb/Jd2xQHcAM8sys1+b2f9GP/YX41uN/1FpWZfgWz3nOuf+Wum5p4DDzOz06P1rgZecczV9KTcL6I1vUT8PTHG++yQ2/6HA1pjsm4H2u/Inkpn9yMwWmtm66Lp/z97b5XhgXj1XMwdfvC+N3r8IMOClWuSIx1HAVy6mX9o59xnwFXB0zHyrnXObY+5/BXSq5bpqI7Zr7avoz13rOx5Y6Pz3BHV1FPC/zrmtMY/9Hf+mFfu6/+Wci1TKksjXndL0hWXiNQG+xn8krGxL9OetwHD8R8Rl+Jbwf7HvjvsBcBzwMzP7HxdtnoD/YszMXgauNbOP8QXoQmq22Tn3KYCZDQKWm9lg59y0mPxL8d0ElW2MY/ngX2fbKh5vh38jqJKZnYr/BPJb4BagCP+6atstUC3n3A4zex7fVfJ09OeLzrmSRswRe3rPHVU8V9uGVkX05+7uGDNrtp95d6/POeeiPTiN1bBr6NedMVS8E+89fB9nRbSVVZXvA68456bD7n7yI/BFItbnwC/w3RCTzawgtoDjP2a+AHyGH03xRm2CRovYfwF3mdnz0eL1HnAF8I1zrnKeeH0MnG9mVinvCdHn9qcP8KVzbtyuB8ysa6V53gd+gH/tVSnHd/PU5BngLTM7GjgX//1DbXLEs54PgYPNrNuu1reZHYbv9/5XHBlrY9col9h+/t51WM77wCAza76f1ne8r/taM2sd0/o+HV+YP6xDJkHvag2pjZn1rnTrhi+gfwP+YmbnmdmhZnaamf3WzHa1xlcAPzCz75vZkfi+7UOrWkn0DaAfvsBMqvRF1+v4vujRwDTnXEUVi6jJTHyLZ1j0/gz8J4e/mNmZ0fx9zex+23vESZMqXv+x0ecexfftPmRmvcysp5ndgn9TuLeaLCuALmZ2lZkdZmY3RH8n1njgx2Z2p5kdbWbHmNktMV+mrgLOMD9iZr8jNpxzf8f37c4EvmHvrph4cqwCuprZCeZHsVQ1Vv4NfBfFDDPLMz8SZAb+DXJ+Nduh1pxz24H/AX4V3SanU7dPCo8ArYDnzewkMzvczK4ws11vBKuAY6N/0477ad3PwHdLPW1+1ElfYBLw512f+qT2VLwbzhn4Vkrs7b5oS/N8/D/nFHxL83mgJ3v6F+8E/oHve30LP7Jhxv5W5Jxbif/C5zxiCnh0XU8CzdgzXrtWoq2rh4Hboi2lEqAvvjX/R+AjfP96e2BTzK9mV/H6C6PL/Cy6jB7AX6OvdSDwY+fcnGqyvIIv7g/ii97ZwG8qzfMavq/6vOg6F+Df3Ha9cf0GOAQ/GqemMdcz8CMunovte40nB/An4DV80d/AvsV919/n4ujzb0Zv64BLKn0iaSjXRn++iy+Wo2q7AOfcl/i/XXN83vfxn/52RmeZgm89L8a/rj5VLKMEOAdog//b/wVYFJNP6sASs89IKGb2KP4b/LNrnFlEUpb6vNOE+QMejsaP7b48cBwRSTAV7/TxF/wBEFOdc7NDhxGRxFK3iYhICtIXliIiKShh3SYdO3Z03bp1S9Ti47Jt2zZatmwZNEOy0LbwPv74YyKRCEcffXTNM2cA7Rd7VLUtvvoK1q6FZs3g6KOhaSN0NC9ZsuQb59xBNc2XsCjdunVj8eLFiVp8XAoLC8nPzw+aIVloW3j5+fkUFRUF3zeThfaLPSpvi7ffhvx8MIO5c6F//8bJYWar45lP3SYiIpVs2gRXXQUVFfCrXzVe4a4NFW8RkRjOwXXXwRdfwMknw9ixoRNVTcVbRCTG44/Dn/4ErVvDs8/6/u5kpOItIhL14Ydwc/TyD48+CocdFjZPdWpVvM2sh/mrUz+TqEAiIiGUlzfhiitg+3a4+mrf553Matvynog/yY2ISFqZPPkwPvgADj8cJk4MnaZmcRdvMxuIP790fa9aIiKSVGbPhj/96bs0bQozZ/r+7mQXV/E2szb4i7j+Z2LjiIg0rrVrYfBgPz1+PJx0UtA4cYv3IJ1x+BMerdn73P97M7MC/AVyyc3NpbCwsN4B66O4uDh4hmShbeEVFRURiUS0LaIyfb+oqIDbbvse33zTgd69N5CXt5xU2Rw1Fu/oFTPOwl+ItFrOucnAZIC8vDwX+sgtHT22h7aF165dO4qKirQtojJ9v7j3XliyBDp2hFGjPqF///zAieIXT8s7H+gG/Dva6m4FZJnZ0c65ExIXTUQkcd59F26/3U9PmwYtW1Z1ic7kFU+f92SgO/7ipb2Bx4DZ+MsaiYiknK1b4YorYOdOuOkmuOCC0Ilqr8aWd/T6cyW77ptZMVDqnKvpeoAiIklp2DBYuRJ69YJ77gmdpm5qfVZB59yYBOQQEWkUM2bA009DdrY//L1Fi9CJ6kaHx4tIxvjsM7jhBj89YQIcdVTYPPWh4i0iGWHHDt/PvXUrXHYZDBkSOlH9qHiLSEYYPRr+8Q845BCYMsVfZCGVqXiLSNqbPx/uvhuaNPF93u3bh05UfyreIpLWvvkGBg3yF1m44w4444zQiRqGireIpC3n4Npr/flL+vSBUaNCJ2o4Kt4ikrYeeQReeQXatfPdJY1x9ffGouItImlp2TIYPtxPT5kCXbuGzdPQVLxFJO2UlMDAgVBW5ocE/uhHoRM1PBVvEUk7w4fDv/4FRx4JDz4YOk1iqHiLSFp58UV47DFo3twf/t6yZehEiaHiLSJp44sv4Gc/89O/+x307h02TyKpeItIWohE/FXfN22C88/3p3pNZyreIpIW7roLFiyA3Fx48snUP/y9JireIpLy/v53GDPGT0+fDp06BY3TKFS8RSSlFRXBlVf6bpMRI+Dss0Mnahwq3iKSspyD66+H1ashLw/uvDN0osaj4i0iKWvaNJg1yw8HnDnTDw/MFCreIpKSPv4YfvELP/3II9CjR9g8jU3FW0RSTlmZvyrOtm2+v/vqq0Mnanwq3iKScm6/Hd5/Hw49FB59NP2HBVZFxVtEUsrcufDAA5CV5fu527QJnSgMFW8RSRlffw0//amfHjcOTj01bJ6QVLxFJCVUVPjCvX499OsHt90WOlFYKt4ikhIefBD++7/hwAP9UZRZWaEThaXiLSJJ7733YORIPz11KnTpEjZPMlDxFpGkVlzshwXu2AE33ggXXxw6UXJQ8RaRpHbTTbBiBRx7LNx7b+g0yUPFW0SS1qxZ/vSuLVrAc89BdnboRMlDxVtEktKqVVBQ4Kd//3s45pigcZKOireIJJ2dO/1h71u2wCWXwNChoRMlHxVvEUk6v/0tLFrkR5U8/nhmHv5eExVvEUkqCxbA+PG+YD/zjB/XLftS8RaRpLFxIwwa5C+y8OtfQ35+6ETJS8VbRJKCczBkCKxZA6edBqNHh06U3FS8RSQpTJoEL77ozxI4cyY0bRo6UXJT8RaR4JYvh1tu8dOTJkG3bkHjpIS4ireZPWNma81si5mtMLMhiQ4mIplh+3Z/+HtpKVxzDQwcGDpRaoi35X0X0M051wa4CLjTzE5MXCwRyRQjRsCyZXDEEfCHP4ROkzriKt7OueXOubJdd6O37glLJSIZ4eWXYeJEaNYMnn0WWrUKnSh1xP2VgJk9AgwGsoH3gdeqmKcAKADIzc2lsLCwQULWVXFxcfAMyULbwisqKiISiWhbRIXcLzZsaM6QIScBzRgy5FO2bFlDyD9Lqv2PmHMu/pnNsoDTgHzgHufcjv3Nm5eX5xYvXlzvgPVRWFhIvgaKAtoWu+Tn51NUVMTSpUtDR0kKofaLSATOPhvefBPOOQdeew2aBB4+kSz/I2a2xDmXV9N8tdpczrmIc24h8F3ghrqGE5HM9rvf+cLdqRM89VT4wp2K6rrJmqI+bxGpg3fegTvu8NNPPQW5uWHzpKoai7eZdTKzgWbWysyyzOwc4ApgXuLjiUg62bLFDwuMRPy47nPPDZ0odcXzhaXDd5E8hi/2q4FfOudeTmQwEUkvzsENN8Dnn8Pxx8Ndd4VOlNpqLN7OuQ3AmY2QRUTS2PTp/rD3nBw/LPCAA0InSm36mkBEEu7TT/3FgwEeegh69gybJx2oeItIQpWX+37u4mK4/HJ/CLzUn4q3iCTUHXfA4sXQtas/6ZSuitMwVLxFJGFef92P6c7K8v3d7dqFTpQ+VLxFJCE2bICf/MRPjx4Np58eNk+6UfEWkQbnnO/bXrcO+vaF228PnSj9qHiLSIN76CGYPRvat/cXEc7KCp0o/ah4i0iDWrrUn6MbYOpUOOSQsHnSlYq3iDSYbdv8sMDychg6FC69NHSi9KXiLSIN5pZb4KOP4Oij4YEHQqdJbyreItIgXngBpkzxh70/95w/DF4SR8VbROrt3/+G667z0/fdB8cdFzZPJlDxFpF62bkTrroKiorgwgv3nMNEEkvFW0TqZfx4WLgQOneGJ57Q4e+NRcVbROps4UIYO9YX7GeegY4dQyfKHCreIlInmzbBlVdCRQX86lfQv3/oRJlFxVtEas05KCiAL76Ak0/2rW9pXCreIlJrU6f6oYGtW/uzBTZrFjpR5lHxFpFa+fBDuOkmP/3oo9C9e9g8mUrFW0TiVlrqD3/fvh2uvtoPEZQwVLxFJG4jR8IHH/jW9sSJodNkNhVvEYnL7NkwYQI0beqv/t66dehEmU3FW0RqtHYtDB7sp8ePh5NOChpHUPEWkRpUVPjLmX3zDZx1Ftx6a+hEAireIlKD+++HN97wR08+/TQ0UdVICvoziMh+vfvunutPTpvmz18iyUHFW0SqtHWrHxa4c6cf133BBaETSSwVbxGp0rBhsHIl9OoF99wTOo1UpuItIvuYOdP3b2dn+2GBLVqETiSVqXiLyF4++wyuv95PT5gARx0VNo9UTcVbRHbbscP3c2/dCpddBkOGhE4k+6PiLSK7jR4N//gHHHKIv5iwroqTvFS8RQSA+fPh7rv9OO4ZM6B9+9CJpDoq3iLCN9/4swQ6B3fcAWecETqR1ETFWyTDOQfXXgtffQV9+sCoUaETSTxUvEUy3COPwCuvQNu2vrukadPQiSQeNRZvMzvAzKaa2Woz22pmS83svMYIJyKJ9dlnLRk+3E9PmQJdu4bNI/GLp+XdFPgCOBNoC4wCnjezbomLJSKJVlIC48YdTVmZHxL44x+HTiS1UeMHJOfcNmBMzEOvmtnnwInAqsTEEpFEGz4cVq1qyZFHwoMPhk4jtVXr3i0zywWOAJZX8VwBUACQm5tLYWFhffPVS3FxcfAMyULbwisqKiISiWT8tnj77Y489tixNG0aYfjw93n33eLQkYJLtf8Rc87FP7NZM2AOsNI5N7S6efPy8tzixYvrGa9+CgsLyc/PD5ohWWhbePn5+RQVFbF06dLQUYJZs8afbGrjRrjxxk94+OEeoSMlhWT5HzGzJc65vJrmi3u0iZk1AaYD5cCwemQTkUAiERg0yBfu88+Hyy77MnQkqaO4ireZGTAVyAUuc87tSGgqEUmIu+6CBQsgNxeefFKHv6eyeFvejwJHARc657YnMI+IJMiiRTBmjJ9++mno1CloHKmneMZ5dwWGAr2BdWZWHL1dlfB0ItIgior82QIjERgxAgYMCJ1I6iueoYKrAX24EklRzvnzc69eDXl5cOedoRNJQ9Dh8SJpbto0mDULWrb0V8hp3jx0ImkIKt4iaWzFCvjFL/z0xInQQ6MC04aKt0iaKiuDgQNh2za48kr4yU9CJ5KGpOItkqZuvx3efx8OPRQefVTDAtONirdIGpo7Fx54ALKyfD93mzahE0lDU/EWSTNffw0//amfHjcOTj01bB5JDBVvkTRSUQGDB8P69dCvH9x2W+hEkigq3iJp5MEHfZfJgQfC9Om+20TSk4q3SJp47z0YOdJPT50KXbqEzSOJpeItkgaKi/3h7zt2wI03wsUXh04kiabiLZIGbr7ZH5Bz7LFw772h00hjUPEWSXGzZsETT0CLFvDcc5CdHTqRNAYVb5EUtmoVFBT46QcegGOOCRpHGpGKt0iK2rnTH/a+ZQtccok/c6BkDhVvkRQ1dqy/wEKXLvD44zr8PdOoeIukoAUL/Hm5zeCZZ/y4bsksKt4iKWbjRn8RYef8yaeS4ILnEoCKt0gKcQ6GDIE1a+C002D06NCJJBQVb5EUMnkyvPiiP0vgzJnQrFnoRBKKirdIili+HH75Sz89aRJ06xY0jgSm4i2SAkpL/eHvpaX+rIEDB4ZOJKGpeIukgBEjYNkyfw3Khx4KnUaSgYq3SJJ75RV4+GHfv/3cc9CqVehEkgxUvEWS2JdfwjXX+Om77oITTgibR5KHirdIkopE/BXfv/0WBgyAW24JnUiSiYq3SJK6916YPx86dYKnnoIm+m+VGNodRJLQO+/AqFF++qmn4DvfCZtHko+Kt0iS2bLFDwuMRHxXybnnhk4kyUjFWyTJ/Pzn8PnncPzx/ktKkaqoeIskkenTYcYMyMmBZ5+FAw4InUiSlYq3SJL49FPf6gZ/IE7PnmHzSHJT8RZJAuXlvp+7uBguv3zP2G6R/VHxFkkCd9wBixdD167+pFO6Ko7URMVbJLDXX4ff/Q6ysvxpXtu1C51IUoGKt0hAGzb4oyjBX1jh9NPD5pHUoeItEohzvm973Tro29df0kwkXnEVbzMbZmaLzazMzKYlOJNIRnjoIZg9G9q39xcRzsoKnUhSSdM45/sKuBM4B8hOXByRzPDBB/4c3QBTp8Ihh4TNI6knruLtnPszgJnlAd9NaCKRNLdtm78STnk5DB0Kl14aOpGkonhb3nExswKgACA3N5fCwsKGXHytFRcXB8+QLLQtvKKiIiKRSNBtcd99R/DRRwfTtes2LrlkCYWFFcGyaL/YI9W2RYMWb+fcZGAyQF5ensvPz2/IxddaYWEhoTMkC20Lr127dhQVFQXbFi+84Pu5DzgAXn65Jd/7Xt8gOXbRfrFHqm0LjTYRaST//jdcd52fvu8++N73wuaR1KbiLdIIdu6Eq66CoiK48EK48cbQiSTVxdVtYmZNo/NmAVlm1gLY6ZzbmchwIuli/HhYuBA6d4YnntDh71J/8ba8RwHbgZHAoOj0qESFEkknCxfC2LG+YE+fDh07hk4k6SDeoYJjgDEJTSKShjZt8t0lFRUwciT84AehE0m6UJ+3SII4BwUF/ovKk0/2rW+RhqLiLZIgU6f6oYGtW/uzBTZrFjqRpBMVb5EE+OgjuPlmP/3oo9C9e9g8kn5UvEUaWGmpP/y9pASuvtr3eYs0NBVvkQY2cqQ/8VT37jBxYug0kq5UvEUa0GuvwYQJ0LSpv/p769ahE0m6UvFuAPn5+QwbNix0DAls7VoYPNhPjx8PJ50UNI6kuYwo3oMHD+aHP/xh6BiSxioq/OXMNmyAs86CW28NnUjSXUYUb5FEu/9+eOMNf/Tk009DE/1nSYJl/C62efNmCgoK6NSpE61bt+bMM89k8eLFu5//9ttvueKKK/jud79LdnY2xxxzDE8++WS1y5w3bx7t2rXjscceS3R8SQKLF++5/uS0af78JSKJltHF2znHBRdcwJdffsmrr77K+++/T9++fenfvz9r164FoLS0lBNOOIFXX32V5cuXc/PNNzN06FDmzZtX5TJfeOEFLr30UiZPnsz111/fmC9HAti6Fa64wp818Kab4IILQieSTNGgF2NINW+++SZLly5lw4YNZGf7S3OOGzeOV155henTp3PbbbfRpUsXRuy62CBQUFDA/PnzefbZZ/lBpRNVTJ48mREjRvDCCy8wYMCARn0tEsawYfDpp9CrF9xzT+g0kkkyungvWbKEkpISDjrooL0eLy0tZeXKlQBEIhHuvvtuZs2axZdffklZWRnl5eX7XHHjpZdeYtKkSbz11lucdtppjfUSJKCZM33/dna2HxbYokXoRJJJMrp4V1RUkJuby9tvv73Pc23atAHgvvvu4/7772fChAkcd9xxtGrVittvv53169fvNX+vXr1YtmwZU6dO5dRTT8V0wua09tlnsKtXbMIEOOqosHkk82R08T7hhBP4+uuvadKkCYcddliV8yxcuJALL7yQq6++GvD95CtWrKBdu3Z7zXfooYfy0EMPkZ+fT0FBAZMnT1YBT1M7dsCVV/r+7ssugyFDQieSTJQxX1hu2bKFpUuX7nU7/PDD6dOnDxdffDFz5szh888/Z9GiRYwePXp3a/yII45g3rx5LFy4kI8++ohhw4bx+eefV7mOww47jDfffJO5c+cydOhQnHON+RKlkYweDe+8A4ccAlOm6Ko4EkbGFO+3336b448/fq/biBEjeO211+jfvz/XXXcdPXv25PLLL+fjjz/m4IMPBmDUqFGcfPLJnHfeefTt25eWLVtyVTVnGurevTuFhYXMmTNHBTwNzZ8Pd9/tx3HPmAHt24dOJJkqI7pNpk2bxrRp0/b7/IQJE5gwYUKVz7Vv354///nP1S6/sLBwr/vdu3fniy++qG1MSXLffOPPEugc/OY3cMYZoRNJJsuYlrdIfTgHP/sZfPUV9OkDo3QFVwlMxVskDo88Ai+/DG3b+u6SphnxmVWSmYq3SA2WLYPhw/30lCnQtWvYPCKg4i1Sre3b/eHvZWV+SOCPfxw6kYiX0sW7pKSEQYMGMXv27NBRJE0NHw7Ll8ORR8KDD4ZOI7JHyhbv9evXc8opp/DHP/6Ryy+/fK8zAYo0hBdf9BcPbt7cH/7esmXoRCJ7pGTxXrFiBb179+ajjz6ivLyckpISzj77bFatWhU6mqSJNWv2HDl5zz3Qu3fYPCKVpVzx/tvf/sZJJ53EunXr2Llz5+7HN2/ezEUXXRQwmaSLSAQGDYKNG+H88+Hmm0MnEtlXShXvWbNmMWDAALZs2bLPkYvZ2dncvuuM+CL1cPfdsGAB5ObCk0/q8HdJTilRvJ1z3HXXXVxzzTWUlJTs9ZyZ0bp1a+bOncvAgQMDJZR0sWiRP3cJ+NO9duoUNo/I/iT9oQaRSIShQ4fy7LPPsn379r2ea9q0KR07dqSwsJCePXsGSijpYvNmf7bASARGjABdT0OSWVIX723btnHxxRezaNGifVrcLVq0oHv37syfP59Oah5JPTkHQ4fCqlWQlwd33hk6kUj1krZ4r1u3jv79+/PZZ59RVla213M5OTn06dOHl156iZycnEAJJZ1MmwazZvnhgDNn+uGBIsksKfu8P/zwQ3r16sUnn3xSZeEeNGgQc+bMUeGWBrFiBfziF3564kTo0SNsHpF4JF3xfuuttzjllFNYv379XkMBwY8o+e1vf8ukSZPIysoKlFDSSVmZP/x92zbf3/2Tn4ROJBKfIMV78eLFnHLKKRQVFe31+IwZMzj33HPZunXrPr+Tk5PDU089xa233tpYMSUD/PrX8N57cOih/mhKDQuUVBGkeI8fP57FixdzzjnnUF5ejnMjTkM1AAAH/klEQVSOcePGcd111+0zosTMaNOmDW+88QY/1lmBpAHNnQv33w9ZWb6fO3rNaZGU0OhfWG7YsIE5c+ZQUVHBsmXLuPLKK2nVqhV//OMf9ynczZo146CDDqKwsJAe6oiUBvT11/DTn/rpsWPh1FPD5hGprUYv3o8//vjuq6pv376dOXPmAFQ5FLBHjx7MmzePgw46qLFjSpobPBjWr4d+/eBXvwqdRqT24uo2MbMOZvaimW0zs9VmdmVdVlZRUcGECRMoLS3d/VhJSck+hTsnJ4d+/frxzjvvqHBLg1u//gDmzoUDD4Tp0323iUiqibflPREoB3KB3sBsM/vAObe8Niv761//yrZt26qdJycnh2uuuYY//OEPNGmSdINhJMXs3AlFRf4kU5s2+WGBa9dmAzB1KnTpEjigSB1Z5RM87TODWUtgE3Csc25F9LHpwJfOuZH7+73WrVu7E088ca/HPvjgg31GmMRq0qQJnTt35vDDD4//FVSjqKiIdu3aNciyUl2qb4tIxBfinTthx46qf1b1WCRSeUlLAejRozcHH9zoLyPppPp+0ZCSZVssWLBgiXMur6b54ml5HwHs3FW4oz4Azqw8o5kVAAXgv2yMLdTl5eVs3ry52hVVVFSwbt062rRpQ/MGOMQtEolU+2aRSZJhWzgHkYjF3Jqwc+ee+/ubjkSaUEMbo1pZWW73rbzc0axZhJycIrRrJMd+kSxSbVvEU7xbAVsqPbYZaF15RufcZGAyQF5enou9us3IkSNZuXIl5eXlNa6wrKyMRYsW0bZt2zji7V9hYSH5+fn1Wka6aKht4Zy/ruOuboiNG+OfruG9u1rZ2dChA7Rv73/GO92mDcT2vuXn51NUVMTSpUvrvS3Sgf5H9kiWbWFxHmwQT/EuBiqPgG0D7HskzX7s2LGDxx57LK7CXVFRwerVqxk7diz3339/vKuQWopEfDGtTfHddb/SGQviZgbt2tWu+O6636JFw75+kVQXT/FeATQ1sx7OuU+ij/UC4v6y8qWXXiKyb+fjbq1bt6asrIzOnTtz/vnnc95559GvX794F5/RqmoFV1WAV678Hs7teXzzZurcFXHAAX6kRm1bwW3b7t0KFpG6q7F4O+e2mdmfgbFmNgQ/2uRi4PR4V3LPPfdQXFy8+37Lli2JRCK0bduWAQMGcMEFF9CvX7+MPbXrrlZwbbshNm2CmFGXNeiw1736tIKzsxt8E4hILcU7VPDnwBPAeuBb4IZ4hwl+8sknLFmyhOzsbJo3b07//v256KKL6NevH127dq1j7ORUWlr74rtxox/KVtdWcPPm1beCd93/4osP6Nev1+7n2rbV+GaRVBZX8XbObQQuqcsKDjzwQKZMmcL3v/99evbsGXdnfCgVFfG3givfj78VvK+2basvvvubzs6O72RKhYWbOOmkuucTkeSS8MPjO3TowJAhQxK9mn2UlsK33zZn+fKa+4Njpzdtql8ruLbFt0MH332hVrCI1EbSXkkHfCt4y5a6DUvz57iKu1t+L23a1K747prOydEpRUWkcTRK8S4rq9uXcZs2+QJeF82aQatW5XznO81rNSqiXTtomtRvaSIiCSze//oXHHKIL8SVzjtVK23a1H5IWocOvhW8YMHfk2LQvYhIQ0tY8d6+Hdasia6kad2GpLVr51vQIiKyt4QV76OO8lcq6dDBX5FbfcEiIg0nYcU7Jwf+4z8StXQRkcymg5VFRFKQireISApS8RYRSUEq3iIiKUjFW0QkBal4i4ikIBVvEZEUpOItIpKCVLxFRFKQubqevLqmBZttAFYnZOHx6wh8EzhDstC22EPbYg9tiz2SZVt0dc4dVNNMCSveycDMFjvn8kLnSAbaFntoW+yhbbFHqm0LdZuIiKQgFW8RkRSU7sV7cugASUTbYg9tiz20LfZIqW2R1n3eIiLpKt1b3iIiaUnFW0QkBal4i4ikoIwq3mbWw8xKzeyZ0FlCMLMDzGyqma02s61mttTMzgudq7GYWQcze9HMtkW3wZWhM4WQ6fvB/qRafcio4g1MBN4NHSKgpsAXwJlAW2AU8LyZdQuYqTFNBMqBXOAq4FEzOyZspCAyfT/Yn5SqDxlTvM1sIFAEzAudJRTn3Dbn3Bjn3CrnXIVz7lXgc+DE0NkSzcxaApcBdzjnip1zC4GXgavDJmt8mbwf7E8q1oeMKN5m1gYYC/xn6CzJxMxygSOA5aGzNIIjgJ3OuRUxj30AZGLLey8Zth/sI1XrQ0YUb2AcMNU5tyZ0kGRhZs2AGcBTzrmPQudpBK2ALZUe2wy0DpAlaWTgflCVlKwPKV+8zazQzNx+bgvNrDdwFvD70FkTraZtETNfE2A6vv93WLDAjasYaFPpsTbA1gBZkkKG7gd7SeX60DR0gPpyzuVX97yZ/RLoBvzbzMC3wLLM7Gjn3AkJD9iIatoWAOY3wlT8l3bnO+d2JDpXklgBNDWzHs65T6KP9SJzuwoydT+oLJ8UrQ9pf3i8meWwd4vrVvwf6wbn3IYgoQIys8eA3sBZzrni0Hkak5k9BzhgCH4bvAac7pzLuAKeyftBrFSuDynf8q6Jc64EKNl138yKgdJk/8Mkgpl1BYYCZcC6aEsDYKhzbkawYI3n58ATwHrgW/w/aCYW7kzfD3ZL5fqQ9i1vEZF0lPJfWIqIZCIVbxGRFKTiLSKSglS8RURSkIq3iEgKUvEWEUlBKt4iIilIxVtEJAX9fxK+PjsDJlloAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing leaky relu in a layer\n",
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1= tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training w/ leaky relu\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct=tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 batch accuracy: 0.86 Validation acc: 0.9044\n",
      "5 batch accuracy: 0.94 Validation acc: 0.9496\n",
      "10 batch accuracy: 0.92 Validation acc: 0.9654\n",
      "15 batch accuracy: 0.94 Validation acc: 0.971\n",
      "20 batch accuracy: 1.0 Validation acc: 0.9764\n",
      "25 batch accuracy: 1.0 Validation acc: 0.9778\n",
      "30 batch accuracy: 0.98 Validation acc: 0.978\n",
      "35 batch accuracy: 1.0 Validation acc: 0.9788\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50 \n",
    "\n",
    "with tf.Session() as sess: \n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"batch accuracy:\", acc_batch, \"Validation acc:\", acc_valid)\n",
    "            \n",
    "    save_path = saver.save(sess, \"./DNNLeakReLu_final.ckpt\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer= tf.summary.FileWriter(\"tf_logs/DNNLeakyReLu2\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exponential linear unit for activation function\n",
    "#more accurate usually but more computationally expensive\n",
    "#can make up for cost with faster convergence rate\n",
    "\n",
    "def elu(z, alpha=1):\n",
    "    return np.where(z <0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#nonzero gradient for z < 0\n",
    "#smooth everywhere (faster gradient descent)\n",
    "#tf has ELU \n",
    "#hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaled exponential linear units (self-normalizing around mean and variance, thus preventing vanishing gradients)\n",
    "#outperforms regular ELUs \n",
    "\n",
    "def selu(z, scale=1.0507009873554804934193349852946, alpha=1.6732632423543772848170429916717):\n",
    "    return scale * elu(z, alpha)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: -0.26 < mean < 0.27, 0.74 < std deviation < 1.27\n",
      "Layer 10: -0.24 < mean < 0.27, 0.74 < std deviation < 1.27\n",
      "Layer 20: -0.17 < mean < 0.18, 0.74 < std deviation < 1.24\n",
      "Layer 30: -0.27 < mean < 0.24, 0.78 < std deviation < 1.20\n",
      "Layer 40: -0.38 < mean < 0.39, 0.74 < std deviation < 1.25\n",
      "Layer 50: -0.27 < mean < 0.31, 0.73 < std deviation < 1.27\n",
      "Layer 60: -0.26 < mean < 0.43, 0.74 < std deviation < 1.35\n",
      "Layer 70: -0.19 < mean < 0.21, 0.75 < std deviation < 1.21\n",
      "Layer 80: -0.18 < mean < 0.16, 0.72 < std deviation < 1.19\n",
      "Layer 90: -0.19 < mean < 0.16, 0.75 < std deviation < 1.20\n"
     ]
    }
   ],
   "source": [
    "# demonstrating self normalization of function (mean close to 0, std dev close to 1 across all layers)\n",
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500,100))\n",
    "for layer in range(100):\n",
    "    W = np.random.normal(size=(100,100), scale = np.sqrt(1/100))\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=1)\n",
    "    stds = np.std(Z, axis=1)\n",
    "    if layer % 10 == 0:\n",
    "        print(\"Layer {}: {:.2f} < mean < {:.2f}, {:.2f} < std deviation < {:.2f}\".format(\n",
    "            layer, means.min(), means.max(), stds.min(), stds.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net with SeLU\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28\n",
    "\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(np.float32, shape=(None, n_inputs), name= \"X\")\n",
    "y = tf.placeholder(np.int32, shape=(None), name = \"y\")\n",
    "\n",
    "with tf.name_scope(\"SeLu_DNN\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate= 0.01\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 40\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for scaling inputs to mean 0 and stddev 1\n",
    "means = X_train.mean(axis=0, keepdims=True)\n",
    "stds = X_train.std(axis=0, keepdims=True) + 1e-10\n",
    "X_val_scaled = (X_valid - means)/ stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 batch acc: 0.92 Val acc: 0.9194\n",
      "5 batch acc: 0.96 Val acc: 0.9546\n",
      "10 batch acc: 0.98 Val acc: 0.9638\n",
      "15 batch acc: 0.96 Val acc: 0.9678\n",
      "20 batch acc: 1.0 Val acc: 0.9682\n",
      "25 batch acc: 1.0 Val acc: 0.9688\n",
      "30 batch acc: 1.0 Val acc: 0.9714\n",
      "35 batch acc: 1.0 Val acc: 0.9718\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_val_scaled, y: y_valid})\n",
    "            print(epoch, \"batch acc:\", acc_batch, \"Val acc:\", acc_valid)\n",
    "    \n",
    "    save_path = saver.save(sess, \"./DNNSeLu_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer= tf.summary.FileWriter(\"tf_logs/DNNSeLu\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch normalization, another technique to combat vanishing gradients\n",
    "#learns optimal scale and mean of inputs for each layer, shifts/scales data set to normalize to those parameters\n",
    "# less sensitive to weight initialization, can learn at higher rates\n",
    "#runtime penalty, by virtue of a more complicated model, the predictions are slower\n",
    "reset_graph()\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "batch_norm_momentum=0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net with elu activation, He init and batch norm at each layer\n",
    "with tf.name_scope(\"BN_DNN\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "    \n",
    "    batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=batch_norm_momentum)\n",
    "    \n",
    "    dense_layer = partial(tf.layers.dense, kernel_initializer=he_init)\n",
    "    \n",
    "    hidden1 = dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(batch_norm_layer(hidden1))\n",
    "    hidden2 = dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(batch_norm_layer(hidden2))\n",
    "    logits_before_bn = dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = batch_norm_layer(logits_before_bn)\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8982\n",
      "1 Validation accuracy: 0.9264\n",
      "2 Validation accuracy: 0.938\n",
      "3 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.957\n",
      "6 Validation accuracy: 0.9618\n",
      "7 Validation accuracy: 0.9628\n",
      "8 Validation accuracy: 0.9666\n",
      "9 Validation accuracy: 0.9682\n",
      "10 Validation accuracy: 0.9686\n",
      "11 Validation accuracy: 0.9704\n",
      "12 Validation accuracy: 0.9708\n",
      "13 Validation accuracy: 0.971\n",
      "14 Validation accuracy: 0.9736\n",
      "15 Validation accuracy: 0.9728\n",
      "16 Validation accuracy: 0.9734\n",
      "17 Validation accuracy: 0.9748\n",
      "18 Validation accuracy: 0.9758\n",
      "19 Validation accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size= 200\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops], feed_dict={training:True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "    \n",
    "    save_path = saver.save(sess, \"./BN_DNN_final.ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer= tf.summary.FileWriter(\"tf_logs/BN_DNN\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient clipping for exploding gradients - useful for RNN\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "learning_rate= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normally here you'd have a normal op[timizer but .minimize() computes gradients and applies them, so \n",
    "#to clip you need compute seperately\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    threshold = 1.0\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var) for grad, var in grads_and_vars]\n",
    "    training_op = optimizer.apply_gradients(capped_gvs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val acc: 0.288\n",
      "1 val acc: 0.7936\n",
      "2 val acc: 0.8798\n",
      "3 val acc: 0.906\n",
      "4 val acc: 0.9164\n",
      "5 val acc: 0.9218\n",
      "6 val acc: 0.9296\n",
      "7 val acc: 0.9358\n",
      "8 val acc: 0.9382\n",
      "9 val acc: 0.9414\n",
      "10 val acc: 0.9456\n",
      "11 val acc: 0.9474\n",
      "12 val acc: 0.9478\n",
      "13 val acc: 0.9534\n",
      "14 val acc: 0.9568\n",
      "15 val acc: 0.9566\n",
      "16 val acc: 0.9574\n",
      "17 val acc: 0.959\n",
      "18 val acc: 0.9622\n",
      "19 val acc: 0.9612\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y:y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X:X_valid, y: y_valid})\n",
    "        print(epoch, \"val acc:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./DNN_grad_clip_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer= tf.summary.FileWriter(\"tf_logs/GC_DNN\", tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(\"./DNN_grad_clip_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "train/gradients/Shape\n",
      "train/gradients/grad_ys_0\n",
      "train/gradients/Fill\n",
      "train/gradients/loss/loss_grad/Reshape/shape\n",
      "train/gradients/loss/loss_grad/Reshape\n",
      "train/gradients/loss/loss_grad/Shape\n",
      "train/gradients/loss/loss_grad/Tile\n",
      "train/gradients/loss/loss_grad/Shape_1\n",
      "train/gradients/loss/loss_grad/Shape_2\n",
      "train/gradients/loss/loss_grad/Const\n",
      "train/gradients/loss/loss_grad/Prod\n",
      "train/gradients/loss/loss_grad/Const_1\n",
      "train/gradients/loss/loss_grad/Prod_1\n",
      "train/gradients/loss/loss_grad/Maximum/y\n",
      "train/gradients/loss/loss_grad/Maximum\n",
      "train/gradients/loss/loss_grad/floordiv\n",
      "train/gradients/loss/loss_grad/Cast\n",
      "train/gradients/loss/loss_grad/truediv\n",
      "train/gradients/zeros_like\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "train/gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "train/gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "train/gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "train/gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "train/clip_by_value/Minimum/y\n",
      "train/clip_by_value/Minimum\n",
      "train/clip_by_value/y\n",
      "train/clip_by_value\n",
      "train/clip_by_value_1/Minimum/y\n",
      "train/clip_by_value_1/Minimum\n",
      "train/clip_by_value_1/y\n",
      "train/clip_by_value_1\n",
      "train/clip_by_value_2/Minimum/y\n",
      "train/clip_by_value_2/Minimum\n",
      "train/clip_by_value_2/y\n",
      "train/clip_by_value_2\n",
      "train/clip_by_value_3/Minimum/y\n",
      "train/clip_by_value_3/Minimum\n",
      "train/clip_by_value_3/y\n",
      "train/clip_by_value_3\n",
      "train/clip_by_value_4/Minimum/y\n",
      "train/clip_by_value_4/Minimum\n",
      "train/clip_by_value_4/y\n",
      "train/clip_by_value_4\n",
      "train/clip_by_value_5/Minimum/y\n",
      "train/clip_by_value_5/Minimum\n",
      "train/clip_by_value_5/y\n",
      "train/clip_by_value_5\n",
      "train/clip_by_value_6/Minimum/y\n",
      "train/clip_by_value_6/Minimum\n",
      "train/clip_by_value_6/y\n",
      "train/clip_by_value_6\n",
      "train/clip_by_value_7/Minimum/y\n",
      "train/clip_by_value_7/Minimum\n",
      "train/clip_by_value_7/y\n",
      "train/clip_by_value_7\n",
      "train/clip_by_value_8/Minimum/y\n",
      "train/clip_by_value_8/Minimum\n",
      "train/clip_by_value_8/y\n",
      "train/clip_by_value_8\n",
      "train/clip_by_value_9/Minimum/y\n",
      "train/clip_by_value_9/Minimum\n",
      "train/clip_by_value_9/y\n",
      "train/clip_by_value_9\n",
      "train/clip_by_value_10/Minimum/y\n",
      "train/clip_by_value_10/Minimum\n",
      "train/clip_by_value_10/y\n",
      "train/clip_by_value_10\n",
      "train/clip_by_value_11/Minimum/y\n",
      "train/clip_by_value_11/Minimum\n",
      "train/clip_by_value_11/y\n",
      "train/clip_by_value_11\n",
      "train/GradientDescent/learning_rate\n",
      "train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "train/GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "#this prints all graph ops, a good way to sort through these is to view in tensorboard to see which you need\n",
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for selecting particular tensors/ops once you know what you need\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"train/GradientDescent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for easier access you can group important ops for quick re-use (no searching)\n",
    "\n",
    "#for op in (X, y, accuracy, training_op):\n",
    "    #tf.add_to_collection(\"important_ops\", op)\n",
    "    \n",
    "#to grab this collection later (after importing the meta graph)\n",
    "#X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./DNN_grad_clip_final.ckpt\n",
      "0 Validation accuracy: 0.9632\n",
      "1 Validation accuracy: 0.9648\n",
      "2 Validation accuracy: 0.9646\n",
      "3 Validation accuracy: 0.9644\n",
      "4 Validation accuracy: 0.9666\n",
      "5 Validation accuracy: 0.967\n",
      "6 Validation accuracy: 0.968\n",
      "7 Validation accuracy: 0.9664\n",
      "8 Validation accuracy: 0.9662\n",
      "9 Validation accuracy: 0.9712\n",
      "10 Validation accuracy: 0.9672\n",
      "11 Validation accuracy: 0.9708\n",
      "12 Validation accuracy: 0.971\n",
      "13 Validation accuracy: 0.9708\n",
      "14 Validation accuracy: 0.9698\n",
      "15 Validation accuracy: 0.9698\n",
      "16 Validation accuracy: 0.971\n",
      "17 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9724\n",
      "19 Validation accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "#continue training after restoring session on pre trained model\n",
    "with tf.Session() as sess:\n",
    "    #restore graph state\n",
    "    saver.restore(sess, \"./DNN_grad_clip_final.ckpt\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./Grad_clip_restored_final.ckpt\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous model had 5 hidden layers and 1 output layer; here we will take those first 3 trained layers\n",
    "# and train a new 4th hidden and output, as well as a new loss and optimizer\n",
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  \n",
    "n_outputs = 10 \n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden4/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9576\n",
      "1 Validation accuracy: 0.9666\n",
      "2 Validation accuracy: 0.9694\n",
      "3 Validation accuracy: 0.9708\n",
      "4 Validation accuracy: 0.9722\n",
      "5 Validation accuracy: 0.9726\n",
      "6 Validation accuracy: 0.9752\n",
      "7 Validation accuracy: 0.9748\n",
      "8 Validation accuracy: 0.9754\n",
      "9 Validation accuracy: 0.9756\n",
      "10 Validation accuracy: 0.9756\n",
      "11 Validation accuracy: 0.9758\n",
      "12 Validation accuracy: 0.975\n",
      "13 Validation accuracy: 0.9756\n",
      "14 Validation accuracy: 0.9756\n",
      "15 Validation accuracy: 0.9768\n",
      "16 Validation accuracy: 0.9764\n",
      "17 Validation accuracy: 0.9764\n",
      "18 Validation accuracy: 0.9762\n",
      "19 Validation accuracy: 0.9774\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       #old\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") #old\n",
    "    #using this stop gradient will freeze all layers below it, and then you can have normal train functions\n",
    "    #hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") #old\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") #new\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         #new\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "#only giving higher level (hidden4 + output) variables to train\n",
    "with tf.name_scope(\"train\"):                                        \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     \n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key hidden1/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-184-a81a2e1dfc56>\", line 7, in <module>\n    restore_saver = tf.train.Saver(reuse_vars) # restore layers 1-3 (they are frozen and will not be trained)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in __init__\n    self.build()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 781, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 400, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key hidden1/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key hidden1/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-a81a2e1dfc56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrestore_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./my_model_final.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         \u001b[0mshould_reraise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_reraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mexception_traceback\u001b[0m  \u001b[0;31m# avoid reference cycles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1750\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1752\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1753\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m       \u001b[0mexception_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key hidden1/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-184-a81a2e1dfc56>\", line 7, in <module>\n    restore_saver = tf.train.Saver(reuse_vars) # restore layers 1-3 (they are frozen and will not be trained)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in __init__\n    self.build()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 781, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 400, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key hidden1/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()\n",
    "\n",
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\")\n",
    "restore_saver = tf.train.Saver(reuse_vars) # restore layers 1-3 (they are frozen and will not be trained)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saverold = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caching the output of frozen layers can significantly improve training time \n",
    "#instead of building batches of input data, you can build batches of cached output data at the end of frozen layers \n",
    "#and feed it to new layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  \n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,name=\"hidden1\") \n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") \n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") \n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden[123]\") \n",
    "restore_saver = tf.train.Saver(reuse_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "newsaver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key hidden1/bias not found in checkpoint\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_1_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_1', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-176-7efcb9245e1f>\", line 2, in <module>\n    restore_saver = tf.train.Saver(reuse_vars)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in __init__\n    self.build()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 781, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 400, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key hidden1/bias not found in checkpoint\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_1_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key hidden1/bias not found in checkpoint\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_1_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-44855f320922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrestore_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./my_model_final.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mh2_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         \u001b[0mshould_reraise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_reraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mexception_traceback\u001b[0m  \u001b[0;31m# avoid reference cycles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1750\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1752\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1753\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m       \u001b[0mexception_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key hidden1/bias not found in checkpoint\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_1_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_1', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-176-7efcb9245e1f>\", line 2, in <module>\n    restore_saver = tf.train.Saver(reuse_vars)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in __init__\n    self.build()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 781, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 400, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key hidden1/bias not found in checkpoint\n\t [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_1_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2, feed_dict={X: X_train})\n",
    "    h2_cache_valid = sess.run(hidden2, feed_dict={X: X_valid}) \n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(len(X_train))\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx], n_batches)\n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "\n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_valid, y: y_valid})             \n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)              \n",
    "\n",
    "    save_path = newsaver.save(sess, \"./DNN_reused_with_cached_layers.final.ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different types of optimizers (faster to find global minima)\n",
    "#momentum optimizer (converges faster, can overshoot. friction hyperparam keeps in check(value between 0-1))\n",
    "MomOptimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "#Nesterov Accelerated Gradient \n",
    "#like momentum but it measures gradient of cost function not at local position but slightly ahead in the direction of the momentum\n",
    "\n",
    "NAGOptimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)\n",
    "\n",
    "#adaptive gradient (AdaGrad)\n",
    "#scales down gradient vector along steepest dimensions, decays learning rate (faster for steep dimensions than gentle slopes)\n",
    "#good for simple quadratics, often stops at local minima rather than global for DNNs\n",
    "\n",
    "AdaOptimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "#RMSprop is a fix to adagrad slowing down too fast to find global, only accumulates gradients from recent iterations\n",
    "#an alternative is AdaDelta\n",
    "\n",
    "RMSOptimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, momentum=0.9, decay=0.9, epsilon=1e-10)\n",
    "\n",
    "#ADAM optimization, essentially a combo of RMSprop and momentum, keeps track of both expon. decaying avg of past gradients (momentum)\n",
    "# and a exponentially decaying avg of past squared gradients (rms)\n",
    "#momen decay init to 0.9, scaling decay init to 0.999, smoothing term 1e-10\n",
    "#good improvement is NAdam, which uses Nesterov momentum. Don't think this is built into TF yet though\n",
    "\n",
    "ADAMOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "#overview of optimizers for reference \n",
    "# http://ruder.io/optimizing-gradient-descent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate scheduling (predefined decay of learning rate to prevent divergence, failure to find optimum \n",
    "# or going back and forth over optimum)\n",
    "\n",
    "#normal net, loss and eval for dnn\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden1, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, activation=tf.nn.relu, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train is where the learning rate decay comes in\n",
    "#remember Adagrad RMSprop and ADAM optimization already contain learning scheduling\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step, decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate,momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 10\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acc val: 0.9662\n",
      "1 acc val: 0.9734\n",
      "2 acc val: 0.9794\n",
      "3 acc val: 0.977\n",
      "4 acc val: 0.9846\n",
      "5 acc val: 0.985\n",
      "6 acc val: 0.985\n",
      "7 acc val: 0.9846\n",
      "8 acc val: 0.9858\n",
      "9 acc val: 0.986\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"acc val:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./Learning_Rate_DNN_final.ckpt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoiding overfitting\n",
    "#obvious early stopping is an option (already done this)\n",
    "#l1 and l2 regularization constrains connection weights\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 \n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")\n",
    "    \n",
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "scale = 0.001 #regularization hyperparameter\n",
    "    \n",
    "#total loss= cross entropy loss and the l1 loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits = logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")\n",
    "                               \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "                               \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val acc: 0.9054\n",
      "1 val acc: 0.9044\n",
      "2 val acc: 0.902\n",
      "3 val acc: 0.9084\n",
      "4 val acc: 0.9092\n",
      "5 val acc: 0.9124\n",
      "6 val acc: 0.9196\n",
      "7 val acc: 0.9196\n",
      "8 val acc: 0.9218\n",
      "9 val acc: 0.9264\n",
      "10 val acc: 0.927\n",
      "11 val acc: 0.9298\n",
      "12 val acc: 0.9288\n",
      "13 val acc: 0.9308\n",
      "14 val acc: 0.932\n",
      "15 val acc: 0.9322\n",
      "16 val acc: 0.9342\n",
      "17 val acc: 0.9356\n",
      "18 val acc: 0.936\n",
      "19 val acc: 0.9344\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print( epoch, \"val acc:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./Regularization_DNN_final.ckpt\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more efficient way to implement this is to create a partial representing a dense layer with kernel regularizer\n",
    "# thus resolving the need for computing regularization in the loss function, it can just be referenced through GraphKeys\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 50\n",
    "n_outputs = 10 \n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "scale = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using partial for new dense layer\n",
    "\n",
    "dense_layer_w_reg = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu, kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = dense_layer_w_reg(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = dense_layer_w_reg(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    hidden3 = dense_layer_w_reg(hidden2, n_hidden3, name=\"hidden3\")\n",
    "    logits = dense_layer_w_reg(hidden3, n_outputs, activation=None, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"base_loss\")\n",
    "    #still need to add in reg losses but don't have to compute them here\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct=tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 20\n",
    "batch_size= 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val acc: 0.919\n",
      "1 val acc: 0.9244\n",
      "2 val acc: 0.9224\n",
      "3 val acc: 0.9278\n",
      "4 val acc: 0.9346\n",
      "5 val acc: 0.937\n",
      "6 val acc: 0.9406\n",
      "7 val acc: 0.9428\n",
      "8 val acc: 0.9474\n",
      "9 val acc: 0.9438\n",
      "10 val acc: 0.9482\n",
      "11 val acc: 0.9496\n",
      "12 val acc: 0.943\n",
      "13 val acc: 0.9522\n",
      "14 val acc: 0.9512\n",
      "15 val acc: 0.9482\n",
      "16 val acc: 0.9506\n",
      "17 val acc: 0.9506\n",
      "18 val acc: 0.9504\n",
      "19 val acc: 0.9472\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X:X_valid, y: y_valid})\n",
    "        print(epoch, \"val acc:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./Kernel_Reg_DNN_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout, the most popular regularization technique, involves randomly dropping a percentage (p) of neurons at every \n",
    "#training step, forcing the remaining neurons to compensate and thus become better at generalizing\n",
    "#it is important to remember the weights must be multiplied by the keep probability (1-p) at the end, otherwise their\n",
    "#signals would be too strong because their are double the amount of neurons when testing vs training\n",
    "#slower convergence, better model\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 50\n",
    "n_outputs = 10 \n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "dropout_rate=0.5 \n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden1_drop= tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden2_drop= tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    \n",
    "    hidden3 = tf.layers.dense(hidden2_drop, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden3_drop= tf.layers.dropout(hidden3, dropout_rate, training=training)\n",
    "    \n",
    "    logits = tf.layers.dense(hidden3_drop, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9, use_nesterov=True)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9062\n",
      "1 Validation accuracy: 0.9388\n",
      "2 Validation accuracy: 0.9496\n",
      "3 Validation accuracy: 0.9538\n",
      "4 Validation accuracy: 0.9568\n",
      "5 Validation accuracy: 0.9602\n",
      "6 Validation accuracy: 0.964\n",
      "7 Validation accuracy: 0.9648\n",
      "8 Validation accuracy: 0.966\n",
      "9 Validation accuracy: 0.9684\n",
      "10 Validation accuracy: 0.9706\n",
      "11 Validation accuracy: 0.9674\n",
      "12 Validation accuracy: 0.9696\n",
      "13 Validation accuracy: 0.9706\n",
      "14 Validation accuracy: 0.971\n",
      "15 Validation accuracy: 0.97\n",
      "16 Validation accuracy: 0.9698\n",
      "17 Validation accuracy: 0.9704\n",
      "18 Validation accuracy: 0.9706\n",
      "19 Validation accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./Dropout_DNN_Final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer= tf.summary.FileWriter(\"tf_logs/DNN_Dropout\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization by weight clipping\n",
    "\n",
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\", collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None\n",
    "    return max_norm\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9226\n",
      "1 Validation accuracy: 0.9428\n",
      "2 Validation accuracy: 0.9494\n",
      "3 Validation accuracy: 0.9614\n",
      "4 Validation accuracy: 0.9636\n",
      "5 Validation accuracy: 0.9664\n",
      "6 Validation accuracy: 0.9712\n",
      "7 Validation accuracy: 0.9738\n",
      "8 Validation accuracy: 0.973\n",
      "9 Validation accuracy: 0.9742\n",
      "10 Validation accuracy: 0.9748\n",
      "11 Validation accuracy: 0.9776\n",
      "12 Validation accuracy: 0.9746\n",
      "13 Validation accuracy: 0.9754\n",
      "14 Validation accuracy: 0.978\n",
      "15 Validation accuracy: 0.9798\n",
      "16 Validation accuracy: 0.9798\n",
      "17 Validation accuracy: 0.9782\n",
      "18 Validation accuracy: 0.9798\n",
      "19 Validation accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "n_epochs=20\n",
    "batch_size=200\n",
    "\n",
    "clip_all_weights= tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch, in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) \n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)               \n",
    "\n",
    "    save_path = saver.save(sess, \"./Clip_DNN_final.ckpt\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another good regularization technique is data augmentation: i.e. expanding your data set by generating skewed \n",
    "#versions of your original data. for example, if i had a set of images, i could crop them, rotate them, change \n",
    "#hue/saturation etc. etc. to generate more instance with variance that would allow the model to learn more generalizable\n",
    "# features. Could be useful on GAN project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
